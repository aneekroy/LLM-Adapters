                                                                                                                                                                             
{'loss': 3.1167, 'grad_norm': 1.336616039276123, 'learning_rate': 2.7e-06, 'epoch': 0.0}
{'loss': 3.2348, 'grad_norm': 2.0778236389160156, 'learning_rate': 5.7000000000000005e-06, 'epoch': 0.01}
{'loss': 2.87, 'grad_norm': 1.117733359336853, 'learning_rate': 8.7e-06, 'epoch': 0.01}
{'loss': 3.0879, 'grad_norm': 1.6424542665481567, 'learning_rate': 1.1700000000000001e-05, 'epoch': 0.01}
{'loss': 2.8449, 'grad_norm': 1.2395447492599487, 'learning_rate': 1.47e-05, 'epoch': 0.01}
{'loss': 2.7722, 'grad_norm': 1.4522346258163452, 'learning_rate': 1.77e-05, 'epoch': 0.02}
{'loss': 2.7898, 'grad_norm': 1.742368459701538, 'learning_rate': 2.07e-05, 'epoch': 0.02}
{'loss': 2.5757, 'grad_norm': 1.4795271158218384, 'learning_rate': 2.37e-05, 'epoch': 0.02}
{'loss': 2.3894, 'grad_norm': 1.2638542652130127, 'learning_rate': 2.6700000000000002e-05, 'epoch': 0.02}
{'loss': 2.3161, 'grad_norm': 1.8540011644363403, 'learning_rate': 2.97e-05, 'epoch': 0.03}
{'loss': 2.2068, 'grad_norm': 2.472282648086548, 'learning_rate': 2.9986428750942448e-05, 'epoch': 0.03}
{'loss': 1.9669, 'grad_norm': 2.658179759979248, 'learning_rate': 2.9971349585322948e-05, 'epoch': 0.03}
{'loss': 1.72, 'grad_norm': 2.579451560974121, 'learning_rate': 2.9956270419703444e-05, 'epoch': 0.03}
{'loss': 1.4656, 'grad_norm': 2.2256360054016113, 'learning_rate': 2.994119125408394e-05, 'epoch': 0.04}
{'loss': 1.366, 'grad_norm': 3.0719292163848877, 'learning_rate': 2.992611208846444e-05, 'epoch': 0.04}
{'loss': 1.2083, 'grad_norm': 1.8937184810638428, 'learning_rate': 2.9911032922844937e-05, 'epoch': 0.04}
{'loss': 1.1955, 'grad_norm': 2.2564327716827393, 'learning_rate': 2.9895953757225433e-05, 'epoch': 0.04}
{'loss': 1.1965, 'grad_norm': 1.7596596479415894, 'learning_rate': 2.988087459160593e-05, 'epoch': 0.05}
{'loss': 1.2164, 'grad_norm': 2.272094249725342, 'learning_rate': 2.986579542598643e-05, 'epoch': 0.05}
{'loss': 1.1882, 'grad_norm': 1.9827511310577393, 'learning_rate': 2.985071626036693e-05, 'epoch': 0.05}
{'loss': 1.1087, 'grad_norm': 1.521257996559143, 'learning_rate': 2.9835637094747422e-05, 'epoch': 0.05}
{'loss': 1.2272, 'grad_norm': 2.800804615020752, 'learning_rate': 2.9820557929127922e-05, 'epoch': 0.06}
{'loss': 1.1604, 'grad_norm': 2.07914662361145, 'learning_rate': 2.9805478763508422e-05, 'epoch': 0.06}
{'loss': 1.2538, 'grad_norm': 1.6757410764694214, 'learning_rate': 2.9790399597888918e-05, 'epoch': 0.06}
{'loss': 1.1763, 'grad_norm': 2.545039415359497, 'learning_rate': 2.9775320432269415e-05, 'epoch': 0.06}
{'loss': 1.1754, 'grad_norm': 1.6357043981552124, 'learning_rate': 2.976024126664991e-05, 'epoch': 0.07}
{'loss': 1.1299, 'grad_norm': 1.2787288427352905, 'learning_rate': 2.974516210103041e-05, 'epoch': 0.07}
{'loss': 1.1784, 'grad_norm': 1.2740569114685059, 'learning_rate': 2.973008293541091e-05, 'epoch': 0.07}
{'loss': 1.2399, 'grad_norm': 1.5433878898620605, 'learning_rate': 2.9715003769791404e-05, 'epoch': 0.07}
{'loss': 1.1216, 'grad_norm': 1.26539945602417, 'learning_rate': 2.9699924604171904e-05, 'epoch': 0.08}
{'loss': 1.1764, 'grad_norm': 2.8954074382781982, 'learning_rate': 2.96848454385524e-05, 'epoch': 0.08}
{'loss': 1.1733, 'grad_norm': 2.830742835998535, 'learning_rate': 2.96697662729329e-05, 'epoch': 0.08}
{'loss': 1.0979, 'grad_norm': 2.013448715209961, 'learning_rate': 2.9654687107313396e-05, 'epoch': 0.08}
{'loss': 1.1917, 'grad_norm': 2.6786162853240967, 'learning_rate': 2.9639607941693893e-05, 'epoch': 0.09}
{'loss': 1.1589, 'grad_norm': 1.565200924873352, 'learning_rate': 2.9624528776074392e-05, 'epoch': 0.09}
{'loss': 1.1549, 'grad_norm': 1.5962742567062378, 'learning_rate': 2.960944961045489e-05, 'epoch': 0.09}
{'loss': 1.1628, 'grad_norm': 1.4295321702957153, 'learning_rate': 2.9594370444835385e-05, 'epoch': 0.09}
{'loss': 1.2287, 'grad_norm': 1.6793410778045654, 'learning_rate': 2.9579291279215885e-05, 'epoch': 0.1}
{'loss': 1.0992, 'grad_norm': 1.2936323881149292, 'learning_rate': 2.956421211359638e-05, 'epoch': 0.1}
{'loss': 1.1911, 'grad_norm': 2.060739517211914, 'learning_rate': 2.9549132947976878e-05, 'epoch': 0.1}
{'loss': 1.1491, 'grad_norm': 1.733328104019165, 'learning_rate': 2.9534053782357378e-05, 'epoch': 0.1}
{'loss': 1.1001, 'grad_norm': 1.440209984779358, 'learning_rate': 2.9518974616737874e-05, 'epoch': 0.11}
{'loss': 1.1572, 'grad_norm': 1.457545280456543, 'learning_rate': 2.9503895451118374e-05, 'epoch': 0.11}
{'loss': 1.1516, 'grad_norm': 2.3658649921417236, 'learning_rate': 2.9488816285498867e-05, 'epoch': 0.11}
{'loss': 1.1728, 'grad_norm': 1.8407213687896729, 'learning_rate': 2.9473737119879367e-05, 'epoch': 0.11}
{'loss': 1.1988, 'grad_norm': 1.7008846998214722, 'learning_rate': 2.9458657954259867e-05, 'epoch': 0.12}
{'loss': 1.1894, 'grad_norm': 1.5156108140945435, 'learning_rate': 2.9443578788640363e-05, 'epoch': 0.12}
{'loss': 1.0998, 'grad_norm': 1.9520683288574219, 'learning_rate': 2.942849962302086e-05, 'epoch': 0.12}
{'loss': 1.0847, 'grad_norm': 2.1148171424865723, 'learning_rate': 2.941342045740136e-05, 'epoch': 0.12}
{'loss': 1.226, 'grad_norm': 1.8037445545196533, 'learning_rate': 2.9398341291781856e-05, 'epoch': 0.13}
{'loss': 1.127, 'grad_norm': 1.6842398643493652, 'learning_rate': 2.9383262126162355e-05, 'epoch': 0.13}
{'loss': 1.1489, 'grad_norm': 2.1341333389282227, 'learning_rate': 2.936818296054285e-05, 'epoch': 0.13}
{'loss': 1.2423, 'grad_norm': 1.9912337064743042, 'learning_rate': 2.9353103794923348e-05, 'epoch': 0.13}
{'loss': 1.1683, 'grad_norm': 1.836287260055542, 'learning_rate': 2.9338024629303848e-05, 'epoch': 0.14}
{'loss': 1.1554, 'grad_norm': 1.6738476753234863, 'learning_rate': 2.932294546368434e-05, 'epoch': 0.14}
{'loss': 1.1465, 'grad_norm': 1.3708723783493042, 'learning_rate': 2.930786629806484e-05, 'epoch': 0.14}
{'loss': 1.1486, 'grad_norm': 1.4079865217208862, 'learning_rate': 2.9292787132445337e-05, 'epoch': 0.14}
{'loss': 1.1108, 'grad_norm': 1.6822799444198608, 'learning_rate': 2.9277707966825837e-05, 'epoch': 0.15}
{'loss': 1.166, 'grad_norm': 1.985125184059143, 'learning_rate': 2.9262628801206334e-05, 'epoch': 0.15}
{'loss': 1.1815, 'grad_norm': 1.7564998865127563, 'learning_rate': 2.924754963558683e-05, 'epoch': 0.15}
{'loss': 1.1975, 'grad_norm': 1.5057426691055298, 'learning_rate': 2.923247046996733e-05, 'epoch': 0.15}
{'loss': 1.0862, 'grad_norm': 1.8564690351486206, 'learning_rate': 2.921739130434783e-05, 'epoch': 0.16}
{'loss': 1.2061, 'grad_norm': 1.489380955696106, 'learning_rate': 2.9202312138728323e-05, 'epoch': 0.16}
{'loss': 1.1429, 'grad_norm': 1.7817697525024414, 'learning_rate': 2.9187232973108822e-05, 'epoch': 0.16}
{'loss': 1.1546, 'grad_norm': 1.376105546951294, 'learning_rate': 2.917215380748932e-05, 'epoch': 0.16}
{'loss': 1.1212, 'grad_norm': 3.1981191635131836, 'learning_rate': 2.915707464186982e-05, 'epoch': 0.17}
{'loss': 1.2092, 'grad_norm': 3.321173667907715, 'learning_rate': 2.9141995476250315e-05, 'epoch': 0.17}
{'loss': 1.0969, 'grad_norm': 1.9587973356246948, 'learning_rate': 2.912691631063081e-05, 'epoch': 0.17}
{'loss': 1.0567, 'grad_norm': 1.7118695974349976, 'learning_rate': 2.911183714501131e-05, 'epoch': 0.17}
{'loss': 1.1516, 'grad_norm': 1.8960906267166138, 'learning_rate': 2.9096757979391808e-05, 'epoch': 0.18}
{'loss': 1.0442, 'grad_norm': 1.785401463508606, 'learning_rate': 2.9081678813772304e-05, 'epoch': 0.18}
{'loss': 1.147, 'grad_norm': 1.1975599527359009, 'learning_rate': 2.9066599648152804e-05, 'epoch': 0.18}
{'loss': 1.2269, 'grad_norm': 1.55039381980896, 'learning_rate': 2.90515204825333e-05, 'epoch': 0.18}
{'loss': 1.1955, 'grad_norm': 1.7469125986099243, 'learning_rate': 2.9036441316913797e-05, 'epoch': 0.19}
{'loss': 1.1101, 'grad_norm': 1.932210087776184, 'learning_rate': 2.9021362151294297e-05, 'epoch': 0.19}
{'loss': 1.1141, 'grad_norm': 1.3263425827026367, 'learning_rate': 2.9006282985674793e-05, 'epoch': 0.19}
{'loss': 1.1507, 'grad_norm': 1.387186050415039, 'learning_rate': 2.8991203820055293e-05, 'epoch': 0.19}
{'loss': 1.1313, 'grad_norm': 2.0887820720672607, 'learning_rate': 2.8976124654435786e-05, 'epoch': 0.2}
{'loss': 1.0747, 'grad_norm': 1.5536905527114868, 'learning_rate': 2.8961045488816286e-05, 'epoch': 0.2}
{'loss': 1.1171, 'grad_norm': 4.015822887420654, 'learning_rate': 2.8945966323196785e-05, 'epoch': 0.2}
{'loss': 1.1691, 'grad_norm': 1.332231044769287, 'learning_rate': 2.8930887157577282e-05, 'epoch': 0.2}
{'loss': 1.1411, 'grad_norm': 1.523514747619629, 'learning_rate': 2.891580799195778e-05, 'epoch': 0.21}
{'loss': 1.1261, 'grad_norm': 2.1536386013031006, 'learning_rate': 2.8900728826338275e-05, 'epoch': 0.21}
{'loss': 1.2527, 'grad_norm': 1.9106521606445312, 'learning_rate': 2.8885649660718775e-05, 'epoch': 0.21}
{'loss': 1.11, 'grad_norm': 1.7676920890808105, 'learning_rate': 2.8870570495099274e-05, 'epoch': 0.21}
{'loss': 1.1866, 'grad_norm': 1.9882805347442627, 'learning_rate': 2.8855491329479767e-05, 'epoch': 0.22}
{'loss': 1.1547, 'grad_norm': 2.1784274578094482, 'learning_rate': 2.8840412163860267e-05, 'epoch': 0.22}
{'loss': 1.1081, 'grad_norm': 2.0699872970581055, 'learning_rate': 2.8825332998240767e-05, 'epoch': 0.22}
{'loss': 1.1173, 'grad_norm': 1.9732486009597778, 'learning_rate': 2.8810253832621263e-05, 'epoch': 0.22}
{'loss': 1.1917, 'grad_norm': 1.4074196815490723, 'learning_rate': 2.879517466700176e-05, 'epoch': 0.23}
{'loss': 1.1681, 'grad_norm': 1.3284683227539062, 'learning_rate': 2.8780095501382256e-05, 'epoch': 0.23}
{'loss': 1.0876, 'grad_norm': 1.8208774328231812, 'learning_rate': 2.8765016335762756e-05, 'epoch': 0.23}
{'loss': 1.1093, 'grad_norm': 2.121994972229004, 'learning_rate': 2.8749937170143253e-05, 'epoch': 0.23}
{'loss': 1.1017, 'grad_norm': 1.7560832500457764, 'learning_rate': 2.873485800452375e-05, 'epoch': 0.24}
{'loss': 1.1604, 'grad_norm': 1.7387585639953613, 'learning_rate': 2.871977883890425e-05, 'epoch': 0.24}
{'loss': 1.172, 'grad_norm': 2.4175989627838135, 'learning_rate': 2.8704699673284745e-05, 'epoch': 0.24}
{'loss': 1.192, 'grad_norm': 1.6644102334976196, 'learning_rate': 2.868962050766524e-05, 'epoch': 0.24}
{'loss': 1.1316, 'grad_norm': 1.6211285591125488, 'learning_rate': 2.867454134204574e-05, 'epoch': 0.25}
{'loss': 1.1122, 'grad_norm': 2.3402833938598633, 'learning_rate': 2.8659462176426238e-05, 'epoch': 0.25}
{'loss': 1.0739, 'grad_norm': 1.972571611404419, 'learning_rate': 2.8644383010806738e-05, 'epoch': 0.25}
{'loss': 1.2052, 'grad_norm': 1.5744988918304443, 'learning_rate': 2.8629303845187234e-05, 'epoch': 0.25}
{'loss': 1.0872, 'grad_norm': 2.284113645553589, 'learning_rate': 2.861422467956773e-05, 'epoch': 0.26}
{'loss': 1.1689, 'grad_norm': 2.333562135696411, 'learning_rate': 2.859914551394823e-05, 'epoch': 0.26}
{'loss': 1.1218, 'grad_norm': 1.716639757156372, 'learning_rate': 2.8584066348328727e-05, 'epoch': 0.26}
{'loss': 1.1163, 'grad_norm': 1.7559298276901245, 'learning_rate': 2.8568987182709223e-05, 'epoch': 0.26}
{'loss': 1.0966, 'grad_norm': 1.8924462795257568, 'learning_rate': 2.8553908017089723e-05, 'epoch': 0.27}
{'loss': 1.1894, 'grad_norm': 1.5526341199874878, 'learning_rate': 2.853882885147022e-05, 'epoch': 0.27}
{'loss': 1.1486, 'grad_norm': 1.7221120595932007, 'learning_rate': 2.852374968585072e-05, 'epoch': 0.27}
{'loss': 1.2011, 'grad_norm': 1.2759203910827637, 'learning_rate': 2.8508670520231212e-05, 'epoch': 0.27}
{'loss': 1.1319, 'grad_norm': 1.5845041275024414, 'learning_rate': 2.8493591354611712e-05, 'epoch': 0.28}
{'loss': 1.1229, 'grad_norm': 1.6868382692337036, 'learning_rate': 2.8478512188992212e-05, 'epoch': 0.28}
{'loss': 1.1659, 'grad_norm': 2.0736083984375, 'learning_rate': 2.8463433023372705e-05, 'epoch': 0.28}
{'loss': 1.0644, 'grad_norm': 1.2324997186660767, 'learning_rate': 2.8448353857753205e-05, 'epoch': 0.28}
{'loss': 1.1316, 'grad_norm': 1.421320915222168, 'learning_rate': 2.8433274692133704e-05, 'epoch': 0.29}
{'loss': 1.1238, 'grad_norm': 1.5345232486724854, 'learning_rate': 2.84181955265142e-05, 'epoch': 0.29}
{'loss': 1.0966, 'grad_norm': 1.8777559995651245, 'learning_rate': 2.8403116360894697e-05, 'epoch': 0.29}
{'loss': 1.1654, 'grad_norm': 2.360743761062622, 'learning_rate': 2.8388037195275194e-05, 'epoch': 0.29}
{'loss': 1.1132, 'grad_norm': 1.7046977281570435, 'learning_rate': 2.8372958029655693e-05, 'epoch': 0.3}
{'loss': 1.1664, 'grad_norm': 2.26131010055542, 'learning_rate': 2.8357878864036193e-05, 'epoch': 0.3}
{'loss': 1.1339, 'grad_norm': 1.4528675079345703, 'learning_rate': 2.8342799698416686e-05, 'epoch': 0.3}
{'loss': 1.1058, 'grad_norm': 1.3614786863327026, 'learning_rate': 2.8327720532797186e-05, 'epoch': 0.3}
{'loss': 1.0484, 'grad_norm': 1.3233566284179688, 'learning_rate': 2.8312641367177683e-05, 'epoch': 0.31}
{'loss': 1.1956, 'grad_norm': 1.4913917779922485, 'learning_rate': 2.8297562201558182e-05, 'epoch': 0.31}
{'loss': 1.1505, 'grad_norm': 1.8782849311828613, 'learning_rate': 2.828248303593868e-05, 'epoch': 0.31}
{'loss': 1.1412, 'grad_norm': 1.298086404800415, 'learning_rate': 2.8267403870319175e-05, 'epoch': 0.31}
{'loss': 1.1656, 'grad_norm': 1.7319519519805908, 'learning_rate': 2.8252324704699675e-05, 'epoch': 0.32}
{'loss': 1.1079, 'grad_norm': 1.7509928941726685, 'learning_rate': 2.8237245539080175e-05, 'epoch': 0.32}
{'loss': 1.0878, 'grad_norm': 1.0328311920166016, 'learning_rate': 2.8222166373460668e-05, 'epoch': 0.32}
{'loss': 1.1488, 'grad_norm': 1.6966761350631714, 'learning_rate': 2.8207087207841168e-05, 'epoch': 0.32}
{'loss': 1.1993, 'grad_norm': 1.9627273082733154, 'learning_rate': 2.8192008042221664e-05, 'epoch': 0.33}
{'loss': 1.1315, 'grad_norm': 1.6128454208374023, 'learning_rate': 2.817692887660216e-05, 'epoch': 0.33}
{'loss': 1.1093, 'grad_norm': 1.439134955406189, 'learning_rate': 2.816184971098266e-05, 'epoch': 0.33}
{'loss': 1.0514, 'grad_norm': 1.4149811267852783, 'learning_rate': 2.8146770545363157e-05, 'epoch': 0.33}
{'loss': 1.1204, 'grad_norm': 1.4987472295761108, 'learning_rate': 2.8131691379743657e-05, 'epoch': 0.34}
{'loss': 1.1067, 'grad_norm': 1.3215947151184082, 'learning_rate': 2.811661221412415e-05, 'epoch': 0.34}
{'loss': 1.1141, 'grad_norm': 1.8168644905090332, 'learning_rate': 2.810153304850465e-05, 'epoch': 0.34}
{'loss': 1.0784, 'grad_norm': 1.9600896835327148, 'learning_rate': 2.808645388288515e-05, 'epoch': 0.34}
{'loss': 1.118, 'grad_norm': 1.6634172201156616, 'learning_rate': 2.8071374717265646e-05, 'epoch': 0.35}
{'loss': 1.101, 'grad_norm': 1.4546080827713013, 'learning_rate': 2.8056295551646142e-05, 'epoch': 0.35}
{'loss': 1.128, 'grad_norm': 1.612533688545227, 'learning_rate': 2.8041216386026642e-05, 'epoch': 0.35}
{'loss': 1.0323, 'grad_norm': 1.7987984418869019, 'learning_rate': 2.8026137220407138e-05, 'epoch': 0.35}
{'loss': 1.1588, 'grad_norm': 1.9134845733642578, 'learning_rate': 2.8011058054787638e-05, 'epoch': 0.36}
{'loss': 1.1675, 'grad_norm': 1.607842206954956, 'learning_rate': 2.799597888916813e-05, 'epoch': 0.36}
{'loss': 1.1446, 'grad_norm': 2.0703160762786865, 'learning_rate': 2.798089972354863e-05, 'epoch': 0.36}
{'loss': 1.1099, 'grad_norm': 1.5897458791732788, 'learning_rate': 2.796582055792913e-05, 'epoch': 0.36}
{'loss': 1.1206, 'grad_norm': 1.6348108053207397, 'learning_rate': 2.7950741392309627e-05, 'epoch': 0.37}
{'loss': 1.1083, 'grad_norm': 1.7006725072860718, 'learning_rate': 2.7935662226690124e-05, 'epoch': 0.37}
{'loss': 1.0994, 'grad_norm': 1.4943702220916748, 'learning_rate': 2.792058306107062e-05, 'epoch': 0.37}
{'loss': 1.225, 'grad_norm': 1.9284045696258545, 'learning_rate': 2.790550389545112e-05, 'epoch': 0.37}
{'loss': 1.0769, 'grad_norm': 1.580970287322998, 'learning_rate': 2.7890424729831616e-05, 'epoch': 0.38}
{'loss': 1.0875, 'grad_norm': 1.8051273822784424, 'learning_rate': 2.7875345564212113e-05, 'epoch': 0.38}
{'loss': 1.2034, 'grad_norm': 1.7291557788848877, 'learning_rate': 2.7860266398592612e-05, 'epoch': 0.38}
{'loss': 1.1343, 'grad_norm': 1.3833348751068115, 'learning_rate': 2.7845187232973112e-05, 'epoch': 0.38}
{'loss': 1.146, 'grad_norm': 1.7375041246414185, 'learning_rate': 2.7830108067353605e-05, 'epoch': 0.39}
{'loss': 1.1095, 'grad_norm': 2.1994431018829346, 'learning_rate': 2.7815028901734105e-05, 'epoch': 0.39}
{'loss': 1.0496, 'grad_norm': 1.5487178564071655, 'learning_rate': 2.77999497361146e-05, 'epoch': 0.39}
{'loss': 1.0975, 'grad_norm': 1.7398873567581177, 'learning_rate': 2.77848705704951e-05, 'epoch': 0.39}
{'loss': 1.1015, 'grad_norm': 1.3734766244888306, 'learning_rate': 2.7769791404875598e-05, 'epoch': 0.4}
{'loss': 1.1386, 'grad_norm': 1.7379677295684814, 'learning_rate': 2.7754712239256094e-05, 'epoch': 0.4}
{'loss': 1.1175, 'grad_norm': 1.741451382637024, 'learning_rate': 2.7739633073636594e-05, 'epoch': 0.4}
{'loss': 1.1758, 'grad_norm': 1.4790154695510864, 'learning_rate': 2.772455390801709e-05, 'epoch': 0.4}
{'loss': 1.1397, 'grad_norm': 1.0997401475906372, 'learning_rate': 2.7709474742397587e-05, 'epoch': 0.41}
{'loss': 1.1137, 'grad_norm': 1.274293065071106, 'learning_rate': 2.7694395576778087e-05, 'epoch': 0.41}
{'loss': 1.1971, 'grad_norm': 1.5333812236785889, 'learning_rate': 2.7679316411158583e-05, 'epoch': 0.41}
{'loss': 1.2099, 'grad_norm': 1.2688024044036865, 'learning_rate': 2.7664237245539083e-05, 'epoch': 0.41}
{'loss': 1.143, 'grad_norm': 2.086120128631592, 'learning_rate': 2.764915807991958e-05, 'epoch': 0.42}
{'loss': 1.1304, 'grad_norm': 1.800601601600647, 'learning_rate': 2.7634078914300076e-05, 'epoch': 0.42}
{'loss': 1.0923, 'grad_norm': 1.5158953666687012, 'learning_rate': 2.7618999748680575e-05, 'epoch': 0.42}
{'loss': 1.0729, 'grad_norm': 2.1045169830322266, 'learning_rate': 2.760392058306107e-05, 'epoch': 0.42}
{'loss': 1.2186, 'grad_norm': 1.7956870794296265, 'learning_rate': 2.7588841417441568e-05, 'epoch': 0.43}
{'loss': 1.1351, 'grad_norm': 2.74247145652771, 'learning_rate': 2.7573762251822068e-05, 'epoch': 0.43}
{'loss': 1.1509, 'grad_norm': 2.042179584503174, 'learning_rate': 2.7558683086202564e-05, 'epoch': 0.43}
{'loss': 1.0924, 'grad_norm': 1.3109359741210938, 'learning_rate': 2.754360392058306e-05, 'epoch': 0.43}
{'loss': 1.1506, 'grad_norm': 1.5978505611419678, 'learning_rate': 2.7528524754963557e-05, 'epoch': 0.44}
{'loss': 1.1041, 'grad_norm': 1.6087719202041626, 'learning_rate': 2.7513445589344057e-05, 'epoch': 0.44}
{'loss': 1.1351, 'grad_norm': 1.7605491876602173, 'learning_rate': 2.7498366423724557e-05, 'epoch': 0.44}
{'loss': 1.184, 'grad_norm': 1.7951098680496216, 'learning_rate': 2.748328725810505e-05, 'epoch': 0.44}
{'loss': 1.1348, 'grad_norm': 1.6947860717773438, 'learning_rate': 2.746820809248555e-05, 'epoch': 0.45}
{'loss': 1.0967, 'grad_norm': 1.556885004043579, 'learning_rate': 2.745312892686605e-05, 'epoch': 0.45}
{'loss': 1.1623, 'grad_norm': 1.482837438583374, 'learning_rate': 2.7438049761246546e-05, 'epoch': 0.45}
{'loss': 1.1105, 'grad_norm': 1.908939003944397, 'learning_rate': 2.7422970595627042e-05, 'epoch': 0.45}
{'loss': 1.1035, 'grad_norm': 1.4680092334747314, 'learning_rate': 2.740789143000754e-05, 'epoch': 0.46}
{'loss': 1.1457, 'grad_norm': 1.7302716970443726, 'learning_rate': 2.739281226438804e-05, 'epoch': 0.46}
{'loss': 1.1078, 'grad_norm': 2.273613452911377, 'learning_rate': 2.737773309876854e-05, 'epoch': 0.46}
{'loss': 1.0783, 'grad_norm': 2.019880771636963, 'learning_rate': 2.736265393314903e-05, 'epoch': 0.46}
{'loss': 1.0913, 'grad_norm': 1.5320312976837158, 'learning_rate': 2.734757476752953e-05, 'epoch': 0.47}
{'loss': 1.1759, 'grad_norm': 1.6202312707901, 'learning_rate': 2.7332495601910028e-05, 'epoch': 0.47}
{'loss': 1.1022, 'grad_norm': 1.9744101762771606, 'learning_rate': 2.7317416436290524e-05, 'epoch': 0.47}
{'loss': 1.0812, 'grad_norm': 1.6572743654251099, 'learning_rate': 2.7302337270671024e-05, 'epoch': 0.47}
{'loss': 1.0867, 'grad_norm': 1.4004504680633545, 'learning_rate': 2.728725810505152e-05, 'epoch': 0.48}
{'loss': 1.1465, 'grad_norm': 1.7770376205444336, 'learning_rate': 2.727217893943202e-05, 'epoch': 0.48}
{'loss': 1.1047, 'grad_norm': 1.5713807344436646, 'learning_rate': 2.7257099773812517e-05, 'epoch': 0.48}
{'loss': 1.0987, 'grad_norm': 1.5244371891021729, 'learning_rate': 2.7242020608193013e-05, 'epoch': 0.48}
{'loss': 1.1118, 'grad_norm': 1.8420950174331665, 'learning_rate': 2.7226941442573513e-05, 'epoch': 0.49}
{'loss': 1.1414, 'grad_norm': 1.5218687057495117, 'learning_rate': 2.721186227695401e-05, 'epoch': 0.49}
{'loss': 1.1054, 'grad_norm': 1.8393747806549072, 'learning_rate': 2.7196783111334506e-05, 'epoch': 0.49}
{'loss': 1.1654, 'grad_norm': 1.9695087671279907, 'learning_rate': 2.7181703945715005e-05, 'epoch': 0.49}
{'loss': 1.1749, 'grad_norm': 1.8682953119277954, 'learning_rate': 2.7166624780095502e-05, 'epoch': 0.5}
{'loss': 1.0787, 'grad_norm': 1.2540971040725708, 'learning_rate': 2.7151545614476e-05, 'epoch': 0.5}
{'loss': 1.1735, 'grad_norm': 1.493602991104126, 'learning_rate': 2.7136466448856495e-05, 'epoch': 0.5}
{'loss': 1.0863, 'grad_norm': 1.6923186779022217, 'learning_rate': 2.7121387283236995e-05, 'epoch': 0.5}
{'loss': 1.0587, 'grad_norm': 1.6758513450622559, 'learning_rate': 2.7106308117617494e-05, 'epoch': 0.51}
{'loss': 1.0966, 'grad_norm': 1.6204180717468262, 'learning_rate': 2.709122895199799e-05, 'epoch': 0.51}
{'loss': 1.2924, 'grad_norm': 1.6096786260604858, 'learning_rate': 2.7076149786378487e-05, 'epoch': 0.51}
{'loss': 1.1579, 'grad_norm': 1.5634088516235352, 'learning_rate': 2.7061070620758987e-05, 'epoch': 0.51}
{'loss': 1.065, 'grad_norm': 2.244906425476074, 'learning_rate': 2.7045991455139483e-05, 'epoch': 0.52}
{'loss': 1.1259, 'grad_norm': 1.8657833337783813, 'learning_rate': 2.703091228951998e-05, 'epoch': 0.52}
{'loss': 1.1313, 'grad_norm': 1.6635091304779053, 'learning_rate': 2.7015833123900476e-05, 'epoch': 0.52}
{'loss': 1.0679, 'grad_norm': 1.5884238481521606, 'learning_rate': 2.7000753958280976e-05, 'epoch': 0.52}
{'loss': 1.0348, 'grad_norm': 2.3158016204833984, 'learning_rate': 2.6985674792661476e-05, 'epoch': 0.53}
{'loss': 1.1663, 'grad_norm': 1.8212698698043823, 'learning_rate': 2.697059562704197e-05, 'epoch': 0.53}
{'loss': 1.1086, 'grad_norm': 2.1657872200012207, 'learning_rate': 2.695551646142247e-05, 'epoch': 0.53}
{'loss': 1.0765, 'grad_norm': 2.115453004837036, 'learning_rate': 2.6940437295802965e-05, 'epoch': 0.53}
{'loss': 1.0821, 'grad_norm': 1.7248111963272095, 'learning_rate': 2.6925358130183465e-05, 'epoch': 0.54}
{'loss': 1.1088, 'grad_norm': 1.7305911779403687, 'learning_rate': 2.691027896456396e-05, 'epoch': 0.54}
{'loss': 1.0785, 'grad_norm': 2.612495183944702, 'learning_rate': 2.6895199798944458e-05, 'epoch': 0.54}
{'loss': 1.1291, 'grad_norm': 1.2819344997406006, 'learning_rate': 2.6880120633324958e-05, 'epoch': 0.54}
{'loss': 1.0904, 'grad_norm': 1.9438563585281372, 'learning_rate': 2.6865041467705454e-05, 'epoch': 0.55}
{'loss': 1.1204, 'grad_norm': 1.8804649114608765, 'learning_rate': 2.684996230208595e-05, 'epoch': 0.55}
{'loss': 1.1294, 'grad_norm': 1.4810256958007812, 'learning_rate': 2.683488313646645e-05, 'epoch': 0.55}
{'loss': 1.1681, 'grad_norm': 3.1804473400115967, 'learning_rate': 2.6819803970846947e-05, 'epoch': 0.55}
{'loss': 1.0896, 'grad_norm': 2.012680768966675, 'learning_rate': 2.6804724805227446e-05, 'epoch': 0.56}
{'loss': 1.1414, 'grad_norm': 1.5749012231826782, 'learning_rate': 2.6789645639607943e-05, 'epoch': 0.56}
{'loss': 1.0709, 'grad_norm': 2.839733839035034, 'learning_rate': 2.677456647398844e-05, 'epoch': 0.56}
{'loss': 1.1133, 'grad_norm': 2.043178081512451, 'learning_rate': 2.675948730836894e-05, 'epoch': 0.56}
{'loss': 1.1026, 'grad_norm': 1.6219162940979004, 'learning_rate': 2.6744408142749432e-05, 'epoch': 0.57}
{'loss': 1.1762, 'grad_norm': 1.6304234266281128, 'learning_rate': 2.6729328977129932e-05, 'epoch': 0.57}
{'loss': 1.1527, 'grad_norm': 2.186490058898926, 'learning_rate': 2.671575772807238e-05, 'epoch': 0.57}
{'loss': 1.1217, 'grad_norm': 1.3793811798095703, 'learning_rate': 2.670067856245288e-05, 'epoch': 0.57}
{'loss': 1.1098, 'grad_norm': 1.6905524730682373, 'learning_rate': 2.6685599396833375e-05, 'epoch': 0.58}
{'loss': 1.0801, 'grad_norm': 1.9632763862609863, 'learning_rate': 2.6670520231213875e-05, 'epoch': 0.58}
{'loss': 1.1468, 'grad_norm': 2.7194271087646484, 'learning_rate': 2.665544106559437e-05, 'epoch': 0.58}
{'loss': 1.1144, 'grad_norm': 1.848102331161499, 'learning_rate': 2.6640361899974868e-05, 'epoch': 0.58}
{'loss': 1.1181, 'grad_norm': 1.8274288177490234, 'learning_rate': 2.6625282734355368e-05, 'epoch': 0.59}
{'loss': 1.0833, 'grad_norm': 1.7908238172531128, 'learning_rate': 2.6610203568735864e-05, 'epoch': 0.59}
{'loss': 1.1052, 'grad_norm': 2.0015342235565186, 'learning_rate': 2.659512440311636e-05, 'epoch': 0.59}
{'loss': 1.0755, 'grad_norm': 1.442861795425415, 'learning_rate': 2.658004523749686e-05, 'epoch': 0.59}
{'loss': 1.144, 'grad_norm': 2.0984926223754883, 'learning_rate': 2.6564966071877357e-05, 'epoch': 0.6}
{'loss': 1.1596, 'grad_norm': 2.1691737174987793, 'learning_rate': 2.6549886906257853e-05, 'epoch': 0.6}
{'loss': 1.1706, 'grad_norm': 1.9817193746566772, 'learning_rate': 2.6534807740638353e-05, 'epoch': 0.6}
{'loss': 1.1316, 'grad_norm': 1.4202852249145508, 'learning_rate': 2.651972857501885e-05, 'epoch': 0.6}
{'loss': 1.1824, 'grad_norm': 1.6865136623382568, 'learning_rate': 2.650464940939935e-05, 'epoch': 0.61}
{'loss': 1.1625, 'grad_norm': 1.6049929857254028, 'learning_rate': 2.6489570243779842e-05, 'epoch': 0.61}
{'loss': 1.1168, 'grad_norm': 2.256709098815918, 'learning_rate': 2.6474491078160342e-05, 'epoch': 0.61}
{'loss': 1.2075, 'grad_norm': 1.6787389516830444, 'learning_rate': 2.6459411912540842e-05, 'epoch': 0.61}
{'loss': 1.1262, 'grad_norm': 1.8354684114456177, 'learning_rate': 2.6444332746921338e-05, 'epoch': 0.62}
{'loss': 1.0987, 'grad_norm': 1.7208936214447021, 'learning_rate': 2.6429253581301835e-05, 'epoch': 0.62}
{'loss': 1.1174, 'grad_norm': 1.3544706106185913, 'learning_rate': 2.6414174415682335e-05, 'epoch': 0.62}
{'loss': 1.1852, 'grad_norm': 1.6904079914093018, 'learning_rate': 2.639909525006283e-05, 'epoch': 0.62}
{'loss': 1.1193, 'grad_norm': 2.083768129348755, 'learning_rate': 2.638401608444333e-05, 'epoch': 0.63}
{'loss': 1.1344, 'grad_norm': 1.561822533607483, 'learning_rate': 2.6368936918823824e-05, 'epoch': 0.63}
{'loss': 1.0946, 'grad_norm': 1.7593903541564941, 'learning_rate': 2.6353857753204324e-05, 'epoch': 0.63}
{'loss': 1.0431, 'grad_norm': 1.4967403411865234, 'learning_rate': 2.6338778587584823e-05, 'epoch': 0.63}
{'loss': 1.1228, 'grad_norm': 1.460847020149231, 'learning_rate': 2.6323699421965316e-05, 'epoch': 0.64}
{'loss': 1.179, 'grad_norm': 2.9714975357055664, 'learning_rate': 2.6308620256345816e-05, 'epoch': 0.64}
{'loss': 1.1141, 'grad_norm': 1.7618741989135742, 'learning_rate': 2.6293541090726313e-05, 'epoch': 0.64}
{'loss': 1.0706, 'grad_norm': 1.7954519987106323, 'learning_rate': 2.6278461925106812e-05, 'epoch': 0.64}
{'loss': 1.0833, 'grad_norm': 1.5076619386672974, 'learning_rate': 2.626338275948731e-05, 'epoch': 0.65}
{'loss': 1.1385, 'grad_norm': 2.130946636199951, 'learning_rate': 2.6248303593867805e-05, 'epoch': 0.65}
{'loss': 1.1455, 'grad_norm': 1.640435814857483, 'learning_rate': 2.6233224428248305e-05, 'epoch': 0.65}
{'loss': 1.1459, 'grad_norm': 1.8534698486328125, 'learning_rate': 2.62181452626288e-05, 'epoch': 0.65}
{'loss': 1.1264, 'grad_norm': 2.555023193359375, 'learning_rate': 2.6203066097009298e-05, 'epoch': 0.66}
{'loss': 1.107, 'grad_norm': 1.911218285560608, 'learning_rate': 2.6187986931389798e-05, 'epoch': 0.66}
{'loss': 1.0853, 'grad_norm': 2.3021483421325684, 'learning_rate': 2.6172907765770294e-05, 'epoch': 0.66}
{'loss': 1.0882, 'grad_norm': 1.4065319299697876, 'learning_rate': 2.6157828600150794e-05, 'epoch': 0.66}
{'loss': 1.0914, 'grad_norm': 1.801323652267456, 'learning_rate': 2.614274943453129e-05, 'epoch': 0.67}
{'loss': 1.0732, 'grad_norm': 1.6958338022232056, 'learning_rate': 2.6127670268911787e-05, 'epoch': 0.67}
{'loss': 1.0563, 'grad_norm': 2.2626044750213623, 'learning_rate': 2.6112591103292287e-05, 'epoch': 0.67}
{'loss': 1.1506, 'grad_norm': 1.9960602521896362, 'learning_rate': 2.6097511937672783e-05, 'epoch': 0.67}
{'loss': 1.1141, 'grad_norm': 1.698965072631836, 'learning_rate': 2.608243277205328e-05, 'epoch': 0.68}
{'loss': 1.0419, 'grad_norm': 2.16982364654541, 'learning_rate': 2.606735360643378e-05, 'epoch': 0.68}
{'loss': 1.1529, 'grad_norm': 1.6832894086837769, 'learning_rate': 2.6052274440814276e-05, 'epoch': 0.68}
{'loss': 1.1341, 'grad_norm': 1.7466379404067993, 'learning_rate': 2.6037195275194772e-05, 'epoch': 0.68}
{'loss': 1.1038, 'grad_norm': 1.7056653499603271, 'learning_rate': 2.6022116109575272e-05, 'epoch': 0.69}
{'loss': 1.1277, 'grad_norm': 1.9512028694152832, 'learning_rate': 2.600703694395577e-05, 'epoch': 0.69}
{'loss': 1.097, 'grad_norm': 1.8940824270248413, 'learning_rate': 2.5991957778336268e-05, 'epoch': 0.69}
{'loss': 1.0672, 'grad_norm': 1.9892646074295044, 'learning_rate': 2.597687861271676e-05, 'epoch': 0.69}
{'loss': 1.0499, 'grad_norm': 1.763228416442871, 'learning_rate': 2.596179944709726e-05, 'epoch': 0.7}
{'loss': 1.0675, 'grad_norm': 1.1750884056091309, 'learning_rate': 2.594672028147776e-05, 'epoch': 0.7}
{'loss': 1.1603, 'grad_norm': 1.7724474668502808, 'learning_rate': 2.5931641115858257e-05, 'epoch': 0.7}
{'loss': 1.0921, 'grad_norm': 1.577731966972351, 'learning_rate': 2.5916561950238754e-05, 'epoch': 0.7}
{'loss': 1.1582, 'grad_norm': 1.5533332824707031, 'learning_rate': 2.590148278461925e-05, 'epoch': 0.71}
{'loss': 1.1552, 'grad_norm': 1.568207025527954, 'learning_rate': 2.588640361899975e-05, 'epoch': 0.71}
{'loss': 1.1575, 'grad_norm': 2.0401721000671387, 'learning_rate': 2.587132445338025e-05, 'epoch': 0.71}
{'loss': 1.1191, 'grad_norm': 1.8719239234924316, 'learning_rate': 2.5856245287760743e-05, 'epoch': 0.71}
{'loss': 1.0696, 'grad_norm': 1.9914543628692627, 'learning_rate': 2.5841166122141242e-05, 'epoch': 0.72}
{'loss': 1.1145, 'grad_norm': 1.3559404611587524, 'learning_rate': 2.582608695652174e-05, 'epoch': 0.72}
{'loss': 1.2004, 'grad_norm': 1.5088791847229004, 'learning_rate': 2.581100779090224e-05, 'epoch': 0.72}
{'loss': 1.0423, 'grad_norm': 1.7819149494171143, 'learning_rate': 2.5795928625282735e-05, 'epoch': 0.72}
{'loss': 1.0588, 'grad_norm': 2.72841739654541, 'learning_rate': 2.578084945966323e-05, 'epoch': 0.73}
{'loss': 1.077, 'grad_norm': 1.83755624294281, 'learning_rate': 2.576577029404373e-05, 'epoch': 0.73}
{'loss': 1.1605, 'grad_norm': 1.546622395515442, 'learning_rate': 2.5750691128424228e-05, 'epoch': 0.73}
{'loss': 1.1264, 'grad_norm': 2.2136552333831787, 'learning_rate': 2.5735611962804724e-05, 'epoch': 0.73}
{'loss': 1.1106, 'grad_norm': 1.5573482513427734, 'learning_rate': 2.5720532797185224e-05, 'epoch': 0.74}
{'loss': 1.1349, 'grad_norm': 1.63316810131073, 'learning_rate': 2.570545363156572e-05, 'epoch': 0.74}
{'loss': 1.0588, 'grad_norm': 1.4469094276428223, 'learning_rate': 2.5690374465946217e-05, 'epoch': 0.74}
{'loss': 1.1253, 'grad_norm': 2.0782997608184814, 'learning_rate': 2.5675295300326717e-05, 'epoch': 0.74}
{'loss': 1.126, 'grad_norm': 1.7064683437347412, 'learning_rate': 2.5660216134707213e-05, 'epoch': 0.75}
{'loss': 1.2067, 'grad_norm': 1.692258596420288, 'learning_rate': 2.5645136969087713e-05, 'epoch': 0.75}
{'loss': 1.0602, 'grad_norm': 1.4852650165557861, 'learning_rate': 2.5630057803468206e-05, 'epoch': 0.75}
{'loss': 1.1066, 'grad_norm': 1.8364008665084839, 'learning_rate': 2.5614978637848706e-05, 'epoch': 0.75}
{'loss': 1.15, 'grad_norm': 2.5060369968414307, 'learning_rate': 2.5599899472229206e-05, 'epoch': 0.76}
{'loss': 1.0642, 'grad_norm': 1.9315474033355713, 'learning_rate': 2.5584820306609702e-05, 'epoch': 0.76}
{'loss': 1.0295, 'grad_norm': 1.6494375467300415, 'learning_rate': 2.55697411409902e-05, 'epoch': 0.76}
{'loss': 1.1804, 'grad_norm': 1.6041985750198364, 'learning_rate': 2.5554661975370698e-05, 'epoch': 0.76}
{'loss': 1.1075, 'grad_norm': 2.1397831439971924, 'learning_rate': 2.5539582809751195e-05, 'epoch': 0.77}
{'loss': 1.1071, 'grad_norm': 1.9070268869400024, 'learning_rate': 2.5524503644131694e-05, 'epoch': 0.77}
{'loss': 1.1073, 'grad_norm': 2.1829605102539062, 'learning_rate': 2.5509424478512187e-05, 'epoch': 0.77}
{'loss': 1.1365, 'grad_norm': 1.7497516870498657, 'learning_rate': 2.5494345312892687e-05, 'epoch': 0.77}
{'loss': 1.0913, 'grad_norm': 1.6551308631896973, 'learning_rate': 2.5479266147273187e-05, 'epoch': 0.78}
{'loss': 1.0855, 'grad_norm': 1.585120439529419, 'learning_rate': 2.546418698165368e-05, 'epoch': 0.78}
{'loss': 1.0893, 'grad_norm': 1.9744020700454712, 'learning_rate': 2.544910781603418e-05, 'epoch': 0.78}
{'loss': 1.0926, 'grad_norm': 2.0237879753112793, 'learning_rate': 2.5434028650414676e-05, 'epoch': 0.78}
{'loss': 1.1762, 'grad_norm': 2.171600580215454, 'learning_rate': 2.5418949484795176e-05, 'epoch': 0.79}
{'loss': 1.0326, 'grad_norm': 2.2949836254119873, 'learning_rate': 2.5403870319175673e-05, 'epoch': 0.79}
{'loss': 1.0859, 'grad_norm': 1.8273186683654785, 'learning_rate': 2.538879115355617e-05, 'epoch': 0.79}
{'loss': 1.0751, 'grad_norm': 2.4766836166381836, 'learning_rate': 2.537371198793667e-05, 'epoch': 0.79}
{'loss': 1.0287, 'grad_norm': 2.2661216259002686, 'learning_rate': 2.535863282231717e-05, 'epoch': 0.8}
{'loss': 1.0619, 'grad_norm': 1.9303054809570312, 'learning_rate': 2.534355365669766e-05, 'epoch': 0.8}
{'loss': 1.1383, 'grad_norm': 1.7420443296432495, 'learning_rate': 2.532847449107816e-05, 'epoch': 0.8}
{'loss': 1.1438, 'grad_norm': 1.5593841075897217, 'learning_rate': 2.5313395325458658e-05, 'epoch': 0.8}
{'loss': 1.0552, 'grad_norm': 1.6448081731796265, 'learning_rate': 2.5298316159839158e-05, 'epoch': 0.81}
{'loss': 1.1201, 'grad_norm': 1.6498209238052368, 'learning_rate': 2.5283236994219654e-05, 'epoch': 0.81}
{'loss': 1.0752, 'grad_norm': 1.7034711837768555, 'learning_rate': 2.526815782860015e-05, 'epoch': 0.81}
{'loss': 1.0364, 'grad_norm': 2.1173181533813477, 'learning_rate': 2.525307866298065e-05, 'epoch': 0.81}
{'loss': 1.0798, 'grad_norm': 1.9124201536178589, 'learning_rate': 2.5237999497361147e-05, 'epoch': 0.82}
{'loss': 1.1653, 'grad_norm': 2.2256345748901367, 'learning_rate': 2.5222920331741643e-05, 'epoch': 0.82}
{'loss': 1.0629, 'grad_norm': 2.2103636264801025, 'learning_rate': 2.5207841166122143e-05, 'epoch': 0.82}
{'loss': 1.1352, 'grad_norm': 1.9252421855926514, 'learning_rate': 2.519276200050264e-05, 'epoch': 0.82}
{'loss': 1.1737, 'grad_norm': 1.4702730178833008, 'learning_rate': 2.5177682834883136e-05, 'epoch': 0.83}
{'loss': 1.0375, 'grad_norm': 1.6973763704299927, 'learning_rate': 2.5162603669263636e-05, 'epoch': 0.83}
{'loss': 1.141, 'grad_norm': 1.640106439590454, 'learning_rate': 2.5147524503644132e-05, 'epoch': 0.83}
{'loss': 1.1161, 'grad_norm': 1.9255484342575073, 'learning_rate': 2.5132445338024632e-05, 'epoch': 0.83}
{'loss': 1.124, 'grad_norm': 1.4466331005096436, 'learning_rate': 2.5117366172405125e-05, 'epoch': 0.84}
{'loss': 1.0667, 'grad_norm': 1.8060061931610107, 'learning_rate': 2.5102287006785625e-05, 'epoch': 0.84}
{'loss': 1.1082, 'grad_norm': 2.1822304725646973, 'learning_rate': 2.5087207841166124e-05, 'epoch': 0.84}
{'loss': 1.076, 'grad_norm': 1.5351351499557495, 'learning_rate': 2.507212867554662e-05, 'epoch': 0.84}
{'loss': 1.0775, 'grad_norm': 1.7472769021987915, 'learning_rate': 2.5057049509927117e-05, 'epoch': 0.85}
{'loss': 1.1422, 'grad_norm': 1.720596194267273, 'learning_rate': 2.5041970344307614e-05, 'epoch': 0.85}
{'loss': 1.1359, 'grad_norm': 1.4709607362747192, 'learning_rate': 2.5026891178688113e-05, 'epoch': 0.85}
{'loss': 1.1095, 'grad_norm': 1.52529776096344, 'learning_rate': 2.5011812013068613e-05, 'epoch': 0.85}
{'loss': 1.192, 'grad_norm': 1.9569296836853027, 'learning_rate': 2.4996732847449106e-05, 'epoch': 0.86}
{'loss': 1.0864, 'grad_norm': 1.8961488008499146, 'learning_rate': 2.4981653681829606e-05, 'epoch': 0.86}
{'loss': 1.22, 'grad_norm': 1.8096129894256592, 'learning_rate': 2.4966574516210106e-05, 'epoch': 0.86}
{'loss': 1.111, 'grad_norm': 1.983154296875, 'learning_rate': 2.4951495350590602e-05, 'epoch': 0.86}
{'loss': 1.0861, 'grad_norm': 1.9595773220062256, 'learning_rate': 2.49364161849711e-05, 'epoch': 0.87}
{'loss': 1.0687, 'grad_norm': 1.7102375030517578, 'learning_rate': 2.4921337019351595e-05, 'epoch': 0.87}
{'loss': 1.129, 'grad_norm': 1.501648187637329, 'learning_rate': 2.4906257853732095e-05, 'epoch': 0.87}
{'loss': 1.106, 'grad_norm': 1.5278786420822144, 'learning_rate': 2.489117868811259e-05, 'epoch': 0.87}
{'loss': 1.1029, 'grad_norm': 1.947342038154602, 'learning_rate': 2.4876099522493088e-05, 'epoch': 0.88}
{'loss': 1.1122, 'grad_norm': 1.762513279914856, 'learning_rate': 2.4861020356873588e-05, 'epoch': 0.88}
{'loss': 1.1288, 'grad_norm': 1.6005094051361084, 'learning_rate': 2.4845941191254084e-05, 'epoch': 0.88}
{'loss': 1.0617, 'grad_norm': 1.627295970916748, 'learning_rate': 2.483086202563458e-05, 'epoch': 0.88}
{'loss': 1.1467, 'grad_norm': 1.8897671699523926, 'learning_rate': 2.481578286001508e-05, 'epoch': 0.89}
{'loss': 1.1249, 'grad_norm': 2.2044920921325684, 'learning_rate': 2.4800703694395577e-05, 'epoch': 0.89}
{'loss': 1.035, 'grad_norm': 2.281841516494751, 'learning_rate': 2.4785624528776077e-05, 'epoch': 0.89}
{'loss': 1.1556, 'grad_norm': 1.5356138944625854, 'learning_rate': 2.4770545363156573e-05, 'epoch': 0.89}
{'loss': 1.0926, 'grad_norm': 1.682902216911316, 'learning_rate': 2.475546619753707e-05, 'epoch': 0.9}
{'loss': 1.0323, 'grad_norm': 1.7915968894958496, 'learning_rate': 2.474038703191757e-05, 'epoch': 0.9}
{'loss': 1.0965, 'grad_norm': 1.412630319595337, 'learning_rate': 2.4725307866298066e-05, 'epoch': 0.9}
{'loss': 1.1139, 'grad_norm': 2.299987316131592, 'learning_rate': 2.4710228700678562e-05, 'epoch': 0.9}
{'loss': 1.1448, 'grad_norm': 1.31815505027771, 'learning_rate': 2.4695149535059062e-05, 'epoch': 0.91}
{'loss': 1.154, 'grad_norm': 1.6297355890274048, 'learning_rate': 2.4680070369439558e-05, 'epoch': 0.91}
{'loss': 1.0714, 'grad_norm': 1.7072210311889648, 'learning_rate': 2.4664991203820058e-05, 'epoch': 0.91}
{'loss': 1.0765, 'grad_norm': 1.81129789352417, 'learning_rate': 2.464991203820055e-05, 'epoch': 0.91}
{'loss': 1.0851, 'grad_norm': 1.7954076528549194, 'learning_rate': 2.463483287258105e-05, 'epoch': 0.92}
{'loss': 1.1464, 'grad_norm': 1.6830427646636963, 'learning_rate': 2.461975370696155e-05, 'epoch': 0.92}
{'loss': 1.1059, 'grad_norm': 1.7963154315948486, 'learning_rate': 2.4604674541342044e-05, 'epoch': 0.92}
{'loss': 1.0522, 'grad_norm': 1.5190924406051636, 'learning_rate': 2.4589595375722544e-05, 'epoch': 0.92}
{'loss': 1.1162, 'grad_norm': 1.7021193504333496, 'learning_rate': 2.4574516210103043e-05, 'epoch': 0.93}
{'loss': 1.1172, 'grad_norm': 1.7481037378311157, 'learning_rate': 2.455943704448354e-05, 'epoch': 0.93}
{'loss': 1.0485, 'grad_norm': 1.428918480873108, 'learning_rate': 2.4544357878864036e-05, 'epoch': 0.93}
{'loss': 1.1149, 'grad_norm': 1.8365888595581055, 'learning_rate': 2.4529278713244533e-05, 'epoch': 0.93}
{'loss': 1.1678, 'grad_norm': 2.2756810188293457, 'learning_rate': 2.4514199547625032e-05, 'epoch': 0.94}
{'loss': 1.1482, 'grad_norm': 1.4947903156280518, 'learning_rate': 2.4499120382005532e-05, 'epoch': 0.94}
{'loss': 1.135, 'grad_norm': 1.8860280513763428, 'learning_rate': 2.4484041216386025e-05, 'epoch': 0.94}
{'loss': 1.0565, 'grad_norm': 1.8742225170135498, 'learning_rate': 2.4468962050766525e-05, 'epoch': 0.94}
{'loss': 1.1695, 'grad_norm': 1.8320765495300293, 'learning_rate': 2.445388288514702e-05, 'epoch': 0.95}
{'loss': 1.1425, 'grad_norm': 1.9525758028030396, 'learning_rate': 2.443880371952752e-05, 'epoch': 0.95}
{'loss': 1.0866, 'grad_norm': 1.5708529949188232, 'learning_rate': 2.4423724553908018e-05, 'epoch': 0.95}
{'loss': 1.1478, 'grad_norm': 1.5348589420318604, 'learning_rate': 2.4408645388288514e-05, 'epoch': 0.95}
{'loss': 1.078, 'grad_norm': 1.579145073890686, 'learning_rate': 2.4393566222669014e-05, 'epoch': 0.96}
  File "/home/aneek/LLM-Adapters/finetune.py", line 438, in <module>
    fire.Fire(train)
  File "/home/aneek/miniconda3/envs/prune-net/lib/python3.10/site-packages/fire/core.py", line 135, in Fire
    component_trace = _Fire(component, args, parsed_flag_args, context, name)
  File "/home/aneek/miniconda3/envs/prune-net/lib/python3.10/site-packages/fire/core.py", line 468, in _Fire
    component, remaining_args = _CallAndUpdateTrace(
  File "/home/aneek/miniconda3/envs/prune-net/lib/python3.10/site-packages/fire/core.py", line 684, in _CallAndUpdateTrace
    component = fn(*varargs, **kwargs)
  File "/home/aneek/LLM-Adapters/finetune.py", line 367, in train
    trainer.train(resume_from_checkpoint=resume_from_checkpoint)
  File "/home/aneek/miniconda3/envs/prune-net/lib/python3.10/site-packages/transformers/trainer.py", line 2206, in train
    return inner_training_loop(
  File "/home/aneek/miniconda3/envs/prune-net/lib/python3.10/site-packages/transformers/trainer.py", line 2548, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
  File "/home/aneek/miniconda3/envs/prune-net/lib/python3.10/site-packages/transformers/trainer.py", line 3749, in training_step
    loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)
  File "/home/aneek/miniconda3/envs/prune-net/lib/python3.10/site-packages/transformers/trainer.py", line 3836, in compute_loss
    outputs = model(**inputs)
  File "/home/aneek/miniconda3/envs/prune-net/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/aneek/miniconda3/envs/prune-net/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/aneek/miniconda3/envs/prune-net/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1637, in forward
    else self._run_ddp_forward(*inputs, **kwargs)
  File "/home/aneek/miniconda3/envs/prune-net/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1464, in _run_ddp_forward
    return self.module(*inputs, **kwargs)  # type: ignore[index]
  File "/home/aneek/miniconda3/envs/prune-net/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/aneek/miniconda3/envs/prune-net/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/aneek/miniconda3/envs/prune-net/lib/python3.10/site-packages/accelerate/utils/operations.py", line 818, in forward
    return model_forward(*args, **kwargs)
  File "/home/aneek/miniconda3/envs/prune-net/lib/python3.10/site-packages/accelerate/utils/operations.py", line 806, in __call__
    return convert_to_fp32(self.model_forward(*args, **kwargs))
  File "/home/aneek/miniconda3/envs/prune-net/lib/python3.10/site-packages/torch/amp/autocast_mode.py", line 44, in decorate_autocast
    return func(*args, **kwargs)
  File "/home/aneek/miniconda3/envs/prune-net/lib/python3.10/site-packages/peft/peft_model.py", line 1757, in forward
    return self.base_model(
  File "/home/aneek/miniconda3/envs/prune-net/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/aneek/miniconda3/envs/prune-net/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/aneek/miniconda3/envs/prune-net/lib/python3.10/site-packages/peft/tuners/tuners_utils.py", line 193, in forward
    return self.model.forward(*args, **kwargs)
  File "/home/aneek/miniconda3/envs/prune-net/lib/python3.10/site-packages/transformers/utils/generic.py", line 943, in wrapper
    output = func(self, *args, **kwargs)
  File "/home/aneek/miniconda3/envs/prune-net/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py", line 552, in forward
    outputs: BaseModelOutputWithPast = self.model(
  File "/home/aneek/miniconda3/envs/prune-net/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/aneek/miniconda3/envs/prune-net/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/aneek/miniconda3/envs/prune-net/lib/python3.10/site-packages/transformers/utils/generic.py", line 943, in wrapper
    output = func(self, *args, **kwargs)
  File "/home/aneek/miniconda3/envs/prune-net/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py", line 440, in forward
    layer_outputs = decoder_layer(
  File "/home/aneek/miniconda3/envs/prune-net/lib/python3.10/site-packages/transformers/modeling_layers.py", line 83, in __call__
    return super().__call__(*args, **kwargs)
  File "/home/aneek/miniconda3/envs/prune-net/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/aneek/miniconda3/envs/prune-net/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/aneek/miniconda3/envs/prune-net/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py", line 290, in forward
    hidden_states, self_attn_weights = self.self_attn(
  File "/home/aneek/miniconda3/envs/prune-net/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/aneek/miniconda3/envs/prune-net/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/aneek/miniconda3/envs/prune-net/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py", line 236, in forward
    query_states, key_states = apply_rotary_pos_emb(query_states, key_states, cos, sin)
  File "/home/aneek/miniconda3/envs/prune-net/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py", line 134, in apply_rotary_pos_emb
    q_embed = (q * cos) + (rotate_half(q) * sin)
  File "/home/aneek/miniconda3/envs/prune-net/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py", line 109, in rotate_half
    return torch.cat((-x2, x1), dim=-1)
KeyboardInterrupt
[rank0]: Traceback (most recent call last):
[rank0]:   File "/home/aneek/LLM-Adapters/finetune.py", line 438, in <module>
[rank0]:     fire.Fire(train)
[rank0]:   File "/home/aneek/miniconda3/envs/prune-net/lib/python3.10/site-packages/fire/core.py", line 135, in Fire
[rank0]:     component_trace = _Fire(component, args, parsed_flag_args, context, name)
[rank0]:   File "/home/aneek/miniconda3/envs/prune-net/lib/python3.10/site-packages/fire/core.py", line 468, in _Fire
[rank0]:     component, remaining_args = _CallAndUpdateTrace(
[rank0]:   File "/home/aneek/miniconda3/envs/prune-net/lib/python3.10/site-packages/fire/core.py", line 684, in _CallAndUpdateTrace
[rank0]:     component = fn(*varargs, **kwargs)
[rank0]:   File "/home/aneek/LLM-Adapters/finetune.py", line 367, in train
[rank0]:     trainer.train(resume_from_checkpoint=resume_from_checkpoint)
[rank0]:   File "/home/aneek/miniconda3/envs/prune-net/lib/python3.10/site-packages/transformers/trainer.py", line 2206, in train
[rank0]:     return inner_training_loop(
[rank0]:   File "/home/aneek/miniconda3/envs/prune-net/lib/python3.10/site-packages/transformers/trainer.py", line 2548, in _inner_training_loop
[rank0]:     tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
[rank0]:   File "/home/aneek/miniconda3/envs/prune-net/lib/python3.10/site-packages/transformers/trainer.py", line 3749, in training_step
[rank0]:     loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)
[rank0]:   File "/home/aneek/miniconda3/envs/prune-net/lib/python3.10/site-packages/transformers/trainer.py", line 3836, in compute_loss
[rank0]:     outputs = model(**inputs)
[rank0]:   File "/home/aneek/miniconda3/envs/prune-net/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/home/aneek/miniconda3/envs/prune-net/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/home/aneek/miniconda3/envs/prune-net/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1637, in forward
[rank0]:     else self._run_ddp_forward(*inputs, **kwargs)
[rank0]:   File "/home/aneek/miniconda3/envs/prune-net/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1464, in _run_ddp_forward
[rank0]:     return self.module(*inputs, **kwargs)  # type: ignore[index]
[rank0]:   File "/home/aneek/miniconda3/envs/prune-net/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/home/aneek/miniconda3/envs/prune-net/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/home/aneek/miniconda3/envs/prune-net/lib/python3.10/site-packages/accelerate/utils/operations.py", line 818, in forward
[rank0]:     return model_forward(*args, **kwargs)
[rank0]:   File "/home/aneek/miniconda3/envs/prune-net/lib/python3.10/site-packages/accelerate/utils/operations.py", line 806, in __call__
[rank0]:     return convert_to_fp32(self.model_forward(*args, **kwargs))
[rank0]:   File "/home/aneek/miniconda3/envs/prune-net/lib/python3.10/site-packages/torch/amp/autocast_mode.py", line 44, in decorate_autocast
[rank0]:     return func(*args, **kwargs)
[rank0]:   File "/home/aneek/miniconda3/envs/prune-net/lib/python3.10/site-packages/peft/peft_model.py", line 1757, in forward
[rank0]:     return self.base_model(
[rank0]:   File "/home/aneek/miniconda3/envs/prune-net/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/home/aneek/miniconda3/envs/prune-net/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/home/aneek/miniconda3/envs/prune-net/lib/python3.10/site-packages/peft/tuners/tuners_utils.py", line 193, in forward
[rank0]:     return self.model.forward(*args, **kwargs)
[rank0]:   File "/home/aneek/miniconda3/envs/prune-net/lib/python3.10/site-packages/transformers/utils/generic.py", line 943, in wrapper
[rank0]:     output = func(self, *args, **kwargs)
[rank0]:   File "/home/aneek/miniconda3/envs/prune-net/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py", line 552, in forward
[rank0]:     outputs: BaseModelOutputWithPast = self.model(
[rank0]:   File "/home/aneek/miniconda3/envs/prune-net/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/home/aneek/miniconda3/envs/prune-net/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/home/aneek/miniconda3/envs/prune-net/lib/python3.10/site-packages/transformers/utils/generic.py", line 943, in wrapper
[rank0]:     output = func(self, *args, **kwargs)
[rank0]:   File "/home/aneek/miniconda3/envs/prune-net/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py", line 440, in forward
[rank0]:     layer_outputs = decoder_layer(
[rank0]:   File "/home/aneek/miniconda3/envs/prune-net/lib/python3.10/site-packages/transformers/modeling_layers.py", line 83, in __call__
[rank0]:     return super().__call__(*args, **kwargs)
[rank0]:   File "/home/aneek/miniconda3/envs/prune-net/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/home/aneek/miniconda3/envs/prune-net/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/home/aneek/miniconda3/envs/prune-net/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py", line 290, in forward
[rank0]:     hidden_states, self_attn_weights = self.self_attn(
[rank0]:   File "/home/aneek/miniconda3/envs/prune-net/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/home/aneek/miniconda3/envs/prune-net/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/home/aneek/miniconda3/envs/prune-net/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py", line 236, in forward
[rank0]:     query_states, key_states = apply_rotary_pos_emb(query_states, key_states, cos, sin)
[rank0]:   File "/home/aneek/miniconda3/envs/prune-net/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py", line 134, in apply_rotary_pos_emb
[rank0]:     q_embed = (q * cos) + (rotate_half(q) * sin)
[rank0]:   File "/home/aneek/miniconda3/envs/prune-net/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py", line 109, in rotate_half
[rank0]:     return torch.cat((-x2, x1), dim=-1)
[rank0]: KeyboardInterrupt
