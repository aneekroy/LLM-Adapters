{
  "os": "Linux-6.8.0-60-generic-x86_64-with-glibc2.35",
  "python": "CPython 3.10.16",
  "startedAt": "2025-07-06T12:52:59.140851Z",
  "args": [
    "--base_model",
    "/home/aneek/models/Llama-3.2-1B",
    "--data_path",
    "/home/aneek/LLM-Adapters/dataset/winogrande/train.json",
    "--output_dir",
    "./trained_models/llama-winogrande-1B-lora",
    "--batch_size",
    "4",
    "--micro_batch_size",
    "1",
    "--num_epochs",
    "15",
    "--learning_rate",
    "3e-5",
    "--cutoff_len",
    "256",
    "--val_set_size",
    "120",
    "--adapter_name",
    "lora"
  ],
  "program": "/home/aneek/LLM-Adapters/finetune.py",
  "codePath": "finetune.py",
  "git": {
    "remote": "https://github.com/AGI-Edgerunners/LLM-Adapters.git",
    "commit": "816657208af4db747803f87ba40a4c71383fed7a"
  },
  "email": "ar8002@nyu.edu",
  "root": "/home/aneek/LLM-Adapters",
  "host": "LCS2-IITD",
  "executable": "/home/aneek/miniconda3/envs/prune-net/bin/python3.10",
  "codePathLocal": "finetune.py",
  "cpu_count": 48,
  "cpu_count_logical": 96,
  "gpu": "NVIDIA A100 80GB PCIe",
  "gpu_count": 1,
  "disk": {
    "/": {
      "total": "982141468672",
      "used": "68718792704"
    }
  },
  "memory": {
    "total": "1080755433472"
  },
  "cpu": {
    "count": 48,
    "countLogical": 96
  },
  "gpu_nvidia": [
    {
      "name": "NVIDIA A100 80GB PCIe",
      "memoryTotal": "85899345920",
      "cudaCores": 6912,
      "architecture": "Ampere"
    }
  ],
  "cudaVersion": "12.4"
}