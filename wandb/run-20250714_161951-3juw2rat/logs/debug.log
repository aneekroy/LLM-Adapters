2025-07-14 16:19:51,187 INFO    MainThread:235441 [wandb_setup.py:_flush():76] Current SDK version is 0.17.4
2025-07-14 16:19:51,187 INFO    MainThread:235441 [wandb_setup.py:_flush():76] Configure stats pid to 235441
2025-07-14 16:19:51,187 INFO    MainThread:235441 [wandb_setup.py:_flush():76] Loading settings from /home/aneek/.config/wandb/settings
2025-07-14 16:19:51,187 INFO    MainThread:235441 [wandb_setup.py:_flush():76] Loading settings from /home/aneek/LLM-Adapters/wandb/settings
2025-07-14 16:19:51,187 INFO    MainThread:235441 [wandb_setup.py:_flush():76] Loading settings from environment variables: {}
2025-07-14 16:19:51,187 INFO    MainThread:235441 [wandb_setup.py:_flush():76] Applying setup settings: {'_disable_service': False}
2025-07-14 16:19:51,187 INFO    MainThread:235441 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program_relpath': 'ensemble_eval_multi_lora_commonsense.py', 'program_abspath': '/home/aneek/LLM-Adapters/ensemble_eval_multi_lora_commonsense.py', 'program': '/home/aneek/LLM-Adapters/ensemble_eval_multi_lora_commonsense.py'}
2025-07-14 16:19:51,188 INFO    MainThread:235441 [wandb_setup.py:_flush():76] Applying login settings: {}
2025-07-14 16:19:51,188 INFO    MainThread:235441 [wandb_init.py:_log_setup():529] Logging user logs to /home/aneek/LLM-Adapters/wandb/run-20250714_161951-3juw2rat/logs/debug.log
2025-07-14 16:19:51,188 INFO    MainThread:235441 [wandb_init.py:_log_setup():530] Logging internal logs to /home/aneek/LLM-Adapters/wandb/run-20250714_161951-3juw2rat/logs/debug-internal.log
2025-07-14 16:19:51,188 INFO    MainThread:235441 [wandb_init.py:init():569] calling init triggers
2025-07-14 16:19:51,188 INFO    MainThread:235441 [wandb_init.py:init():576] wandb.init called with sweep_config: {}
config: {'dataset': 'hellaswag', 'model': 'Llama-3.2-1B-Instruct', 'base_model': '/home/aneek/models/Llama-3.2-1B-Instruct', 'lora_weights': '/home/aneek/LLM-Adapters/trained_models/llama-commonsense_170k-1B-lora,/home/aneek/LLM-Adapters/trained_models/llama-math_50k-1B-lora,/home/aneek/LLM-Adapters/trained_models/llama-alpaca_data_cleaned-1B-lora', 'batch_size': 16, 'ensemble_rule': 'vote', 'load_8bit': True}
2025-07-14 16:19:51,188 INFO    MainThread:235441 [wandb_init.py:init():619] starting backend
2025-07-14 16:19:51,188 INFO    MainThread:235441 [wandb_init.py:init():623] setting up manager
2025-07-14 16:19:51,189 INFO    MainThread:235441 [backend.py:_multiprocessing_setup():105] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2025-07-14 16:19:51,190 INFO    MainThread:235441 [wandb_init.py:init():631] backend started and connected
2025-07-14 16:19:51,192 INFO    MainThread:235441 [wandb_init.py:init():720] updated telemetry
2025-07-14 16:19:51,196 INFO    MainThread:235441 [wandb_init.py:init():753] communicating run to backend with 90.0 second timeout
2025-07-14 16:19:52,178 INFO    MainThread:235441 [wandb_run.py:_on_init():2402] communicating current version
2025-07-14 16:19:52,263 INFO    MainThread:235441 [wandb_run.py:_on_init():2411] got version response upgrade_message: "wandb version 0.21.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"

2025-07-14 16:19:52,263 INFO    MainThread:235441 [wandb_init.py:init():804] starting run threads in backend
2025-07-14 16:19:56,509 INFO    MainThread:235441 [wandb_run.py:_console_start():2380] atexit reg
2025-07-14 16:19:56,509 INFO    MainThread:235441 [wandb_run.py:_redirect():2235] redirect: wrap_raw
2025-07-14 16:19:56,509 INFO    MainThread:235441 [wandb_run.py:_redirect():2300] Wrapping output streams.
2025-07-14 16:19:56,509 INFO    MainThread:235441 [wandb_run.py:_redirect():2325] Redirects installed.
2025-07-14 16:19:56,511 INFO    MainThread:235441 [wandb_init.py:init():847] run started, returning control to user process
2025-07-14 16:20:02,085 WARNING MsgRouterThr:235441 [router.py:message_loop():77] message_loop has been closed
