2025-07-14 17:14:06,005 INFO    MainThread:278154 [wandb_setup.py:_flush():76] Current SDK version is 0.17.4
2025-07-14 17:14:06,005 INFO    MainThread:278154 [wandb_setup.py:_flush():76] Configure stats pid to 278154
2025-07-14 17:14:06,005 INFO    MainThread:278154 [wandb_setup.py:_flush():76] Loading settings from /home/aneek/.config/wandb/settings
2025-07-14 17:14:06,005 INFO    MainThread:278154 [wandb_setup.py:_flush():76] Loading settings from /home/aneek/LLM-Adapters/wandb/settings
2025-07-14 17:14:06,005 INFO    MainThread:278154 [wandb_setup.py:_flush():76] Loading settings from environment variables: {}
2025-07-14 17:14:06,005 INFO    MainThread:278154 [wandb_setup.py:_flush():76] Applying setup settings: {'_disable_service': False}
2025-07-14 17:14:06,005 INFO    MainThread:278154 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program_relpath': 'commonsense_evaluate.py', 'program_abspath': '/home/aneek/LLM-Adapters/commonsense_evaluate.py', 'program': '/home/aneek/LLM-Adapters/commonsense_evaluate.py'}
2025-07-14 17:14:06,005 INFO    MainThread:278154 [wandb_setup.py:_flush():76] Applying login settings: {}
2025-07-14 17:14:06,005 INFO    MainThread:278154 [wandb_init.py:_log_setup():529] Logging user logs to /home/aneek/LLM-Adapters/wandb/run-20250714_171406-cgxne7sz/logs/debug.log
2025-07-14 17:14:06,005 INFO    MainThread:278154 [wandb_init.py:_log_setup():530] Logging internal logs to /home/aneek/LLM-Adapters/wandb/run-20250714_171406-cgxne7sz/logs/debug-internal.log
2025-07-14 17:14:06,006 INFO    MainThread:278154 [wandb_init.py:init():569] calling init triggers
2025-07-14 17:14:06,006 INFO    MainThread:278154 [wandb_init.py:init():576] wandb.init called with sweep_config: {}
config: {'dataset': 'boolq', 'model': 'Llama-3.2-1B', 'adapter': 'LoRA', 'base_model': '/home/models/Llama-3.2-1B-Instruct/', 'lora_weights': '/home/aneek/LLM-Adapters/trained_models/llama-alpaca_data_cleaned-1B-lora', 'batch_size': 16, 'load_8bit': False}
2025-07-14 17:14:06,006 INFO    MainThread:278154 [wandb_init.py:init():619] starting backend
2025-07-14 17:14:06,006 INFO    MainThread:278154 [wandb_init.py:init():623] setting up manager
2025-07-14 17:14:06,009 INFO    MainThread:278154 [backend.py:_multiprocessing_setup():105] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2025-07-14 17:14:06,011 INFO    MainThread:278154 [wandb_init.py:init():631] backend started and connected
2025-07-14 17:14:06,017 INFO    MainThread:278154 [wandb_init.py:init():720] updated telemetry
2025-07-14 17:14:06,021 INFO    MainThread:278154 [wandb_init.py:init():753] communicating run to backend with 90.0 second timeout
2025-07-14 17:14:10,843 WARNING MainThread:278154 [wandb_init.py:init():1185] interrupted
Traceback (most recent call last):
  File "/home/aneek/miniconda3/envs/llama4env/lib/python3.10/site-packages/wandb/sdk/wandb_init.py", line 1181, in init
    return wi.init()
  File "/home/aneek/miniconda3/envs/llama4env/lib/python3.10/site-packages/wandb/sdk/wandb_init.py", line 756, in init
    result = run_init_handle.wait(
  File "/home/aneek/miniconda3/envs/llama4env/lib/python3.10/site-packages/wandb/sdk/lib/mailbox.py", line 283, in wait
    found, abandoned = self._slot._get_and_clear(timeout=wait_timeout)
  File "/home/aneek/miniconda3/envs/llama4env/lib/python3.10/site-packages/wandb/sdk/lib/mailbox.py", line 130, in _get_and_clear
    if self._wait(timeout=timeout):
  File "/home/aneek/miniconda3/envs/llama4env/lib/python3.10/site-packages/wandb/sdk/lib/mailbox.py", line 126, in _wait
    return self._event.wait(timeout=timeout)
  File "/home/aneek/miniconda3/envs/llama4env/lib/python3.10/threading.py", line 607, in wait
    signaled = self._cond.wait(timeout)
  File "/home/aneek/miniconda3/envs/llama4env/lib/python3.10/threading.py", line 324, in wait
    gotit = waiter.acquire(True, timeout)
KeyboardInterrupt
